return(list(meanRW=meanRW))
}
data_ss <- readRDS("modelPred.RDS")
stanData.SS <- readRDS("stanData.rds")
mes <- c(1,0,1,0,0,1,0,1)
payoff <- c(25,50,75,100,25,50,75,100);
payoff <- payoff/max(payoff) #Scaling
#simulate Bayesian Model
ss.simBayes <- sim_bayes(stanData.SS$nSubjects,stanData.SS$nTrials,stanData.SS$nBandits,stanData.SS$choice,stanData.SS$shock)
#Simulate RW model
fit.rw <- readRDS('fits/v1/r1_RW.fit')
ex.rw <- rstan::extract(fit.rw)
ssLearn <- colMeans(ex.rw$alpha)
ss.simRW <- sim_rw(stanData.SS$nSubjects,stanData.SS$nTrials,stanData.SS$nBandits,stanData.SS$choice,stanData.SS$shock,ssLearn)
#Calculate feature differences (Option A - Option B)
SS.diff.meanBayes <- array(0,dim=c(stanData.SS$nSubjects,stanData.SS$nTrials))
SS.diff.varBayes <- array(0,dim=c(stanData.SS$nSubjects,stanData.SS$nTrials))
SS.diff.meanRW <- array(0,dim=c(stanData.SS$nSubjects,stanData.SS$nTrials))
SS.diff.orig <- array(0,dim=c(stanData.SS$nSubjects,stanData.SS$nTrials))
SS.diff.payoff <- array(0,dim=c(stanData.SS$nSubjects,stanData.SS$nTrials))
for (s in 1:stanData.SS$nSubjects){
for (t in 1:stanData.SS$nTrials){
SS.diff.meanBayes[s,t] = ss.simBayes$meanBayes[s,t,stanData.SS$option_A[s,t]]-ss.simBayes$meanBayes[s,t,stanData.SS$option_B[s,t]]
SS.diff.varBayes[s,t] = ss.simBayes$varBayes[s,t,stanData.SS$option_A[s,t]]-ss.simBayes$varBayes[s,t,stanData.SS$option_B[s,t]]
SS.diff.meanRW[s,t] = ss.simRW$meanRW[s,t,stanData.SS$option_A[s,t]]-ss.simRW$meanRW[s,t,stanData.SS$option_B[s,t]]
SS.diff.orig[s,t] = mes[stanData.SS$option_A[s,t]] - mes[stanData.SS$option_B[s,t]]
SS.diff.payoff[s,t] = payoff[stanData.SS$option_A[s,t]] - payoff[stanData.SS$option_B[s,t]]
}
}
data_ss <- data_ss %>% ungroup() %>% dplyr::mutate(diff.payoff=as.vector(t(SS.diff.payoff)),
diff.meanBayes=as.vector(t(SS.diff.meanBayes)),diff.varBayes=as.vector(t(SS.diff.varBayes)),
diff.meanRW=as.vector(t(SS.diff.meanRW)),diff.orig=as.vector(t(SS.diff.orig)),
optA=as.vector(t(stanData.SS$option_A)),optB=as.vector(t(stanData.SS$option_B)))
dataSS <- data_ss %>% dplyr::mutate(keyA = case_when(CSchosen==optA~1,CSchosen==optB~-1)) %>% filter(!is.na(RT),!is.na(SS)) #%>%
#mutate(across(c("keyA","diff.payoff","diff.orig","diff.meanRW","diff.meanBayes","diff.varBayes"), ~.x*-1))
for (row in 1:nrow(dataSS)){
if (dataSS$i[row] < .5){
dataSS$keyA[row] <- dataSS$keyA[row]*-1
dataSS$diff.payoff[row] <- dataSS$diff.payoff[row]*-1
dataSS$diff.orig[row] <- dataSS$diff.orig[row]*-1
dataSS$diff.meanRW[row] <- dataSS$diff.meanRW[row]*-1
dataSS$diff.meanBayes[row] <- dataSS$diff.meanBayes[row]*-1
dataSS$diff.varBayes[row] <- dataSS$diff.varBayes[row]*-1
}
}
dataSS <- dataSS %>% dplyr::mutate_at(c("keyA","Subject"),as.factor)
dataSS$ss_scaled <- scale(dataSS$SS)[,1]
#Fit Models
SS.modelOrig <- glmer(keyA ~ diff.payoff + diff.orig*ss_scaled + (1|Subject),data=dataSS,family = binomial)
SS.modelRW <- glmer(keyA ~ diff.payoff + diff.meanRW*ss_scaled + (1|Subject),data=dataSS,family = binomial)
SS.modelMeanBayes <- glmer(keyA ~ diff.payoff + diff.meanBayes*ss_scaled + (1|Subject),data=dataSS,family = binomial)
SS.modelVarBayes <- glmer(keyA ~ diff.payoff + diff.varBayes*ss_scaled + (1|Subject),data=dataSS,family = binomial)
#Model Comparison
glmer.MC <- data.frame(Model = c('Original','RW','BLmean','BLvar'),
value = c(AIC(SS.modelOrig),AIC(SS.modelRW),AIC(SS.modelMeanBayes),AIC(SS.modelVarBayes)))
modelOrder <- c("Original","RW","BLmean","BLvar")
aicPlot <- ggplot(glmer.MC, aes(x=factor(Model, level=rev(modelOrder)), y=value, fill=Model)) +
theme_classic() +
geom_bar(stat="identity", position=position_dodge(),size=3) +
ggtitle("Regression \n Model Comparision")+
xlab("Mixed-Effects Models")+
ylab("AIC (lower is better)") +
theme(legend.position = 'none',text=element_text(size=20)) +
scale_fill_manual(values = c("#0070c0","#cc79a7","#e79f00", "#019e73")) +
coord_flip()
#Model Prediction
SS.predictVarBayes <- ggemmeans(SS.modelVarBayes, terms =list(diff.varBayes=seq(-0.5,0.5,0.01),ss_scaled=c(-2,2)),type="fe")
SS.predictMeanBayes <- ggemmeans(SS.modelMeanBayes, terms =list(diff.meanBayes=seq(-1,1,0.01),ss_scaled=c(-2,2)),type="fe")
SS.predictRW <- ggemmeans(SS.modelRW, terms =list(diff.meanRW=seq(-1,1,0.01),ss_scaled=c(-2,2)),type="fe")
SS.predictOrig <- ggemmeans(SS.modelOrig, terms =list(diff.orig=c(-1,1),ss_scaled=c(-2,2)),type="fe")
#Plots
SS.plotVar <- ggplot(SS.predictVarBayes, aes(x=x,y=predicted,fill="#cc79a7")) +
geom_ribbon(aes(ymin=conf.low, ymax=conf.high,alpha=group,),color=NA) +
geom_line(aes(color="#cc79a7",linetype=group),size=1.2) +
theme_classic() +
labs(title="Bayesian Variance",x="Shock Uncertainty Difference \n (A-B)", y = "P(choice = A)") +
scale_alpha_manual(values=c(0.25,0.65),guide=F,name="Sensation-Seeking",labels = c("Low", "High")) +
scale_linetype_manual(values = c("dotted","solid"),name="Sensation-Seeking",labels = c("Low", "High")) +
scale_colour_manual(values = c("#cc79a7", "#cc79a7"),name="Sensation-Seeking",labels = c("Low", "High"),guide=F) +
scale_fill_manual(values = c("#cc79a7", "#cc79a7"),name="Sensation-Seeking",labels = c("Low", "High"),guide=F) +
ylim(0,1) +
theme(legend.position=c(1,1), legend.justification = c(1,1),text=element_text(size=20)) +
geom_hline(yintercept = 0.5, linetype="dashed", color='red', size=1)
SS.plotMean <- ggplot(SS.predictMeanBayes, aes(x=x,y=predicted,fill="#0070c0")) +
geom_ribbon(aes(ymin=conf.low, ymax=conf.high,alpha=group,),color=NA) +
geom_line(aes(color="#0070c0",linetype=group),size=1.2) +
theme_classic() +
labs(title="Bayesian Mean",x="Shock Mean Difference \n (A-B)", y = "P(choice = A)") +
scale_alpha_manual(values=c(0.25,0.65),guide=F,name="Sensation-Seeking",labels = c("Low", "High")) +
scale_linetype_manual(values = c("dotted","solid"),name="Sensation-Seeking",labels = c("Low", "High")) +
scale_colour_manual(values = c("#0070c0", "#0070c0"),name="Sensation-Seeking",labels = c("Low", "High"),guide=F) +
scale_fill_manual(values = c("#0070c0", "#0070c0"),name="Sensation-Seeking",labels = c("Low", "High"),guide=F) +
ylim(0,1) +
theme(legend.position= c(1,1), legend.justification = c(1,1),text=element_text(size=20)) + theme(legend.position = 'none') +
geom_hline(yintercept = 0.5, linetype="dashed", color='red', size=1)
SS.plotRW <- ggplot(SS.predictRW, aes(x=x,y=predicted,fill="#019e73")) +
geom_ribbon(aes(ymin=conf.low, ymax=conf.high,alpha=group,),color=NA) +
geom_line(aes(color="#019e73",linetype=group),size=1.2) +
theme_classic() +
labs(title="Rescorla-Wagner",x="Shock Mean Difference \n (A-B)", y = "P(choice = A)") +
scale_alpha_manual(values=c(0.25,0.65),guide=F,name="Sensation-Seeking",labels = c("Low", "High")) +
scale_linetype_manual(values = c("dotted","solid"),name="Sensation-Seeking",labels = c("Low", "High")) +
scale_colour_manual(values = c("#019e73", "#019e73"),name="Sensation-Seeking",labels = c("Low", "High"),guide=F) +
scale_fill_manual(values = c("#019e73", "#019e73"),name="Sensation-Seeking",labels = c("Low", "High"),guide=F) +
ylim(0,1) +
theme(legend.position= c(1,1), legend.justification = c(1,1),text=element_text(size=20)) + theme(legend.position = 'none') +
geom_hline(yintercept = 0.5, linetype="dashed", color='red', size=1)
SS.plotOrig <- ggplot(SS.predictOrig, aes(x=x,y=predicted,fill="#e79f00")) +
#geom_ribbon(aes(ymin=conf.low, ymax=conf.high,alpha=group,),color=NA) +
geom_line(aes(color="#e79f00",linetype=group),size=1.2) +
geom_point(color="#e79f00",size=3) +
geom_errorbar(aes(x=x,y = predicted,ymin=conf.low,ymax=conf.high,colour="#e79f00"),width=.1,size=1) +
theme_classic() +
labs(title="Original",x="MES Identity \n (A-B)", y = "P(choice = A)") +
scale_alpha_manual(values=c(0.25,0.65),guide=F,name="Sensation-Seeking",labels = c("Low", "High")) +
scale_linetype_manual(values = c("dotted","solid"),name="Sensation-Seeking",labels = c("Low", "High")) +
scale_colour_manual(values = c("#e79f00", "#e79f00"),name="Sensation-Seeking",labels = c("Low", "High"),guide=F) +
scale_fill_manual(values = c("#e79f00", "#e79f00"),name="Sensation-Seeking",labels = c("Low", "High"),guide=F) +
ylim(0,1) +
theme(legend.position= c(1,1), legend.justification = c(1,1),text=element_text(size=20)) + theme(legend.position = 'none') +
geom_hline(yintercept = 0.5, linetype="dashed", color='red', size=1)
plotSS <- SS.plotOrig + SS.plotRW + SS.plotMean + SS.plotVar + plot_layout(nrow=2,ncol=2,guides = "collect") & theme(legend.position = 'bottom')
packages <- c("plyr", 'dplyr','tidyr',  "ggplot2", 'pander', 'emmeans','sjPlot', 'lmerTest', 'data.table', "ggbeeswarm",
'lmerTest',  'brms', 'BayesFactor', "gridExtra", "lsr",'ggridges','cowplot','entropy','zoo','Hmisc',
'DescTools', 'magrittr', 'purrr', 'forcats', 'modelr', 'tidybayes', 'rstan' , 'loo', 'R.matlab','ggpubr','ggeffects','patchwork')
invisible(lapply(packages, require, character.only = TRUE))
aicPlot
plotSS <- SS.plotOrig + SS.plotRW + SS.plotMean + SS.plotVar + plot_layout(nrow=2,ncol=2,guides = "collect") & theme(legend.position = 'bottom')
plotSS
# Response Curve Analysis of Study 2
load("study_2/s2_hp.RData")
load("study_2/s2_pc.RData")
load("study_2/HPstan.RData")
load("study_2/PCstan.RData")
data_hp <- data_hp %>% dplyr::mutate(drug = "Haloperidol")
data_pc <- data_pc %>% dplyr::mutate(drug = "Placebo")
fit.rw.HP <- readRDS("fits/v1/r2_rw.HP.fit")
ex.rw.HP <- rstan::extract(fit.rw.HP)
hpLearn <- colMeans(ex.rw.HP$alpha)
fit.rw.PC <- readRDS("fits/v1/r2_rw.PC.fit")
ex.rw.PC <- rstan::extract(fit.rw.PC)
pcLearn <- colMeans(ex.rw.PC$alpha)
mes <- c(1,0,1,0,0,1,0,1)
payoff <- c(25,50,75,100,25,50,75,100);
payoff <- payoff/max(payoff) #Scaling
#Simulate Bayesian Model
hp.simBayes <- sim_bayes(stanData.HP$nSubjects,stanData.HP$nTrials,stanData.HP$nBandits,stanData.HP$choice_stim,stanData.HP$shock)
pc.simBayes <- sim_bayes(stanData.PC$nSubjects,stanData.PC$nTrials,stanData.PC$nBandits,stanData.PC$choice_stim,stanData.PC$shock)
#Simulate RW model
hp.simRW <- sim_rw(stanData.HP$nSubjects,stanData.HP$nTrials,stanData.HP$nBandits,stanData.HP$choice_stim,stanData.HP$shock,hpLearn)
pc.simRW <- sim_rw(stanData.PC$nSubjects,stanData.PC$nTrials,stanData.PC$nBandits,stanData.PC$choice_stim,stanData.PC$shock,pcLearn)
#Calculate feature differences (Option A - Option B)
HP.diff.meanBayes <- array(0,dim=c(stanData.HP$nSubjects,stanData.HP$nTrials))
HP.diff.varBayes <- array(0,dim=c(stanData.HP$nSubjects,stanData.HP$nTrials))
HP.diff.meanRW <- array(0,dim=c(stanData.HP$nSubjects,stanData.HP$nTrials))
HP.diff.orig <- array(0,dim=c(stanData.HP$nSubjects,stanData.HP$nTrials))
HP.diff.payoff <- array(0,dim=c(stanData.HP$nSubjects,stanData.HP$nTrials))
PC.diff.meanBayes <- array(0,dim=c(stanData.HP$nSubjects,stanData.HP$nTrials))
PC.diff.varBayes <- array(0,dim=c(stanData.HP$nSubjects,stanData.HP$nTrials))
PC.diff.meanRW <- array(0,dim=c(stanData.HP$nSubjects,stanData.HP$nTrials))
PC.diff.orig <- array(0,dim=c(stanData.HP$nSubjects,stanData.HP$nTrials))
PC.diff.payoff <- array(0,dim=c(stanData.HP$nSubjects,stanData.HP$nTrials))
for (s in 1:stanData.HP$nSubjects){
for (t in 1:stanData.HP$nTrials){
# For haloperidol group
HP.diff.meanBayes[s,t] = hp.simBayes$meanBayes[s,t,stanData.HP$option_A[s,t]]-hp.simBayes$meanBayes[s,t,stanData.HP$option_B[s,t]]
HP.diff.varBayes[s,t] = hp.simBayes$varBayes[s,t,stanData.HP$option_A[s,t]]-hp.simBayes$varBayes[s,t,stanData.HP$option_B[s,t]]
HP.diff.meanRW[s,t] = hp.simRW$meanRW[s,t,stanData.HP$option_A[s,t]]-hp.simRW$meanRW[s,t,stanData.HP$option_B[s,t]]
HP.diff.orig[s,t] = mes[stanData.HP$option_A[s,t]] - mes[stanData.HP$option_B[s,t]]
HP.diff.payoff[s,t] = payoff[stanData.HP$option_A[s,t]] - payoff[stanData.HP$option_B[s,t]]
# For placebo group
PC.diff.meanBayes[s,t] = pc.simBayes$meanBayes[s,t,stanData.PC$option_A[s,t]]-pc.simBayes$meanBayes[s,t,stanData.PC$option_B[s,t]]
PC.diff.varBayes[s,t] = pc.simBayes$varBayes[s,t,stanData.PC$option_A[s,t]]-pc.simBayes$varBayes[s,t,stanData.PC$option_B[s,t]]
PC.diff.meanRW[s,t] = pc.simRW$meanRW[s,t,stanData.PC$option_A[s,t]]-pc.simRW$meanRW[s,t,stanData.PC$option_B[s,t]]
PC.diff.orig[s,t] = mes[stanData.PC$option_A[s,t]] - mes[stanData.PC$option_B[s,t]]
PC.diff.payoff[s,t] = payoff[stanData.PC$option_A[s,t]] - payoff[stanData.PC$option_B[s,t]]
}
}
data_hp <- data_hp %>% mutate(diff.payoff=as.vector(t(HP.diff.payoff)),diff.meanBayes=as.vector(t(HP.diff.meanBayes)),diff.varBayes=as.vector(t(HP.diff.varBayes)),
diff.meanRW=as.vector(t(HP.diff.meanRW)),diff.orig=as.vector(t(HP.diff.orig)),
optA=as.vector(t(stanData.HP$option_A)),optB=as.vector(t(stanData.HP$option_B)))
data_pc <- data_pc %>% mutate(diff.payoff=as.vector(t(PC.diff.payoff)),diff.meanBayes=as.vector(t(PC.diff.meanBayes)),diff.varBayes=as.vector(t(PC.diff.varBayes)),
diff.meanRW=as.vector(t(PC.diff.meanRW)),diff.orig=as.vector(t(PC.diff.orig)),
optA=as.vector(t(stanData.PC$option_A)),optB=as.vector(t(stanData.PC$option_B)))
#Bind Data Frame
dataDrug <- rbind(data_hp,data_pc)
dataDrug <- dataDrug %>% dplyr::mutate(keyA = case_when(CSchosen==optA~1,CSchosen==optB~-1)) %>%
filter(!is.na(CSchosen)) #%>%
#mutate(across(c("keyA","diff.payoff","diff.orig","diff.meanRW","diff.meanBayes","diff.varBayes"), ~.x*-1))
for (row in 1:nrow(dataDrug)){
if (dataDrug$i[row] < .5){
dataDrug$keyA[row] <- dataDrug$keyA[row]*-1
dataDrug$diff.payoff[row] <- dataDrug$diff.payoff[row]*-1
dataDrug$diff.orig[row] <- dataDrug$diff.orig[row]*-1
dataDrug$diff.meanRW[row] <- dataDrug$diff.meanRW[row]*-1
dataDrug$diff.meanBayes[row] <- dataDrug$diff.meanBayes[row]*-1
dataDrug$diff.varBayes[row] <- dataDrug$diff.varBayes[row]*-1
}
}
dataDrug <- dataDrug %>% dplyr::mutate_at(c("keyA","drug","Subject"),as.factor)
#Mixed Effects Model Fitting
modelOrig <- glmer(keyA ~ diff.payoff + diff.orig*drug + (1|Subject),data=dataDrug,family = binomial)
modelRW <- glmer(keyA ~ diff.payoff + diff.meanRW*drug + (1|Subject),data=dataDrug,family = binomial)
modelMeanBayes <- glmer(keyA ~ diff.payoff + diff.meanBayes*drug + (1|Subject),data=dataDrug,family = binomial)
modelVarBayes <- glmer(keyA ~ diff.payoff + diff.varBayes*drug + (1|Subject),data=dataDrug,family = binomial)
#Prediction
predictVarBayes <- ggemmeans(modelVarBayes, terms =list(diff.varBayes=seq(-0.5,0.5,0.01),drug=c("Placebo","Haloperidol")),type="fe")
predictMeanBayes <- ggemmeans(modelMeanBayes, terms =list(diff.meanBayes=seq(-1,1,0.01),drug=c("Placebo","Haloperidol")),type="fe")
predictRW <- ggemmeans(modelRW, terms =list(diff.meanRW=seq(-1,1,0.01),drug=c("Placebo","Haloperidol")),type="fe")
predictOrig <- ggemmeans(modelOrig, terms =list(diff.orig=c(-1,1),drug=c("Placebo","Haloperidol")),type="fe")
#Plots
plotVar <- ggplot(predictVarBayes, aes(x=x,y=predicted,fill="#cc79a7")) +
geom_ribbon(aes(ymin=conf.low, ymax=conf.high,alpha=group,),color=NA) +
geom_line(aes(color="#cc79a7",linetype=group),size=1.2) +
theme_classic() +
labs(title="Bayesian Variance",x="Shock Uncertainty Difference \n (A-B)", y = "P(choice = A)") +
scale_alpha_manual(values=c(0.25,0.65),guide=F,name="Drug") +
scale_linetype_manual(values = c("dotted","solid"),name="Drug") +
scale_colour_manual(values = c("#cc79a7", "#cc79a7"),name="Drug",guide=F) +
scale_fill_manual(values = c("#cc79a7", "#cc79a7"),name="Drug",guide=F) +
ylim(0,1) +
theme(legend.position=c(1,1), legend.justification = c(1,1),text=element_text(size=20)) +
geom_hline(yintercept = 0.5, linetype="dashed", color='red', size=1)
plotMean <- ggplot(predictMeanBayes, aes(x=x,y=predicted,fill="#0070c0")) +
geom_ribbon(aes(ymin=conf.low, ymax=conf.high,alpha=group,),color=NA) +
geom_line(aes(color="#0070c0",linetype=group),size=1.2) +
theme_classic() +
labs(title="Bayesian Mean",x="Shock Mean Difference \n (A-B)", y = "P(choice = A)") +
scale_alpha_manual(values=c(0.25,0.65),guide=F,name="Drug") +
scale_linetype_manual(values = c("dotted","solid"),name="Drug") +
scale_colour_manual(values = c("#0070c0", "#0070c0"),name="Drug",guide=F) +
scale_fill_manual(values = c("#0070c0", "#0070c0"),name="Drug",guide=F) +
ylim(0,1) +
theme(legend.position= c(1,1), legend.justification = c(1,1),text=element_text(size=20)) +# theme(legend.position = 'none') +
geom_hline(yintercept = 0.5, linetype="dashed", color='red', size=1)
plotRW <- ggplot(predictRW, aes(x=x,y=predicted,fill="#019e73")) +
geom_ribbon(aes(ymin=conf.low, ymax=conf.high,alpha=group,),color=NA) +
geom_line(aes(color="#019e73",linetype=group),size=1.2) +
theme_classic() +
labs(title="Rescorla-Wagner",x="Shock Mean Difference \n (A-B)", y = "P(choice = A)") +
scale_alpha_manual(values=c(0.25,0.65),guide=F,name="Drug") +
scale_linetype_manual(values = c("dotted","solid"),name="Drug") +
scale_colour_manual(values = c("#019e73", "#019e73"),name="Drug",guide=F) +
scale_fill_manual(values = c("#019e73", "#019e73"),name="Drug",guide=F) +
ylim(0,1) +
theme(legend.position= c(1,1), legend.justification = c(1,1),text=element_text(size=20)) + #theme(legend.position = 'none') +
geom_hline(yintercept = 0.5, linetype="dashed", color='red', size=1)
plotOrig <- ggplot(predictOrig, aes(x=x,y=predicted,color="#e79f00")) +
#geom_ribbon(aes(ymin=conf.low, ymax=conf.high,alpha=group,)) +
geom_line(aes(color="#e79f00",linetype=group),size=1.2) +
geom_point(color="#e79f00",size=3) +
geom_errorbar(aes(x=x,y = predicted,ymin=conf.low,ymax=conf.high,colour="#e79f00"),width=.1,size=1) +
theme_classic() +
labs(title="Original",x="MES Identity \n (A-B)", y = "P(choice = A)") +
scale_alpha_manual(values=c(0.25,0.65),guide=F,name="Drug") +
scale_linetype_manual(values = c("dotted","solid"),name="Drug") +
scale_colour_manual(values = c("#e79f00", "#e79f00"),name="Drug",guide=F) +
scale_fill_manual(values = c("#e79f00", "#e79f00"),name="Drug",guide=F) +
ylim(0,1) +
theme(legend.position= c(1,1), legend.justification = c(1,1),text=element_text(size=20)) + #theme(legend.position = 'none') +
geom_hline(yintercept = 0.5, linetype="dashed", color='red', size=1)
drugPlot<- plotOrig+ plotRW + plotMean + plotVar + plot_layout(nrow=2,ncol=2,guide='collect') & theme(legend.position = 'bottom')
drugPlot
plot(dataSS$diff.meanBayes,dataSS$diff.varBayes)
knitr::opts_chunk$set(echo = TRUE)
rm(list=ls())
packages <- c("plyr", 'dplyr','tidyr',  "ggplot2", 'pander', 'emmeans','sjPlot', 'lmerTest', 'data.table', "ggbeeswarm",
'lmerTest',  'brms', 'BayesFactor', "gridExtra", "lsr",'ggridges','cowplot','entropy','zoo','Hmisc',
'DescTools', 'magrittr', 'purrr', 'forcats', 'modelr', 'tidybayes', 'rstan' , 'loo', 'R.matlab','ggpubr','ggeffects','patchwork')
invisible(lapply(packages, require, character.only = TRUE))
sim_bayes <- function(nSubjects, nTrials, nBandits, choice, shock){
#initialise alpha and beta counts
alpha <- array(1, dim=c(nSubjects, nTrials, nBandits))
beta <- array(1, dim=c(nSubjects, nTrials, nBandits))
for (s in 1:nSubjects){
for (t in 2:nTrials){
alpha[s,t,] = alpha[s,t-1,]
beta[s,t,] = beta[s,t-1,]
if (choice[s,t-1]>0){ #check for missing trials
if (shock[s,t-1] == 1){
alpha[s,t,choice[s,t-1]] = alpha[s,t,choice[s,t-1]] + 1
}
else if(shock[s,t-1] == 0){
beta[s,t,choice[s,t-1]] = beta[s,t,choice[s,t-1]] + 1
}
}
}
}
meanBayes = alpha/(alpha + beta)
varBayes = sqrt((alpha* beta)/(((alpha+beta)^2)*(alpha+beta+1)))
return(list(meanBayes=meanBayes, varBayes=varBayes, alpha=alpha, beta=beta))
}
sim_rw <- function(nSubjects,nTrials,nBandits,choice,shock,learningR,init=0.5){
meanRW <- array(0,dim=c(nSubjects,nTrials,nBandits))
meanRW[,1,] <- init
for (s in 1:nSubjects){
for (t in 2:nTrials){
meanRW[s,t,] = meanRW[s,t-1,]
if (choice[s,t-1]>0){
meanRW[s,t,choice[s,t-1]] = meanRW[s,t,choice[s,t-1]] + learningR[s] * (shock[s,t-1] - meanRW[s,t,choice[s,t-1]])
}
}
}
return(list(meanRW=meanRW))
}
data_ss <- readRDS("modelPred.RDS")
stanData.SS <- readRDS("stanData.rds")
mes <- c(1,0,1,0,0,1,0,1)
payoff <- c(25,50,75,100,25,50,75,100);
payoff <- payoff/max(payoff) #Scaling
#simulate Bayesian Model
ss.simBayes <- sim_bayes(stanData.SS$nSubjects,stanData.SS$nTrials,stanData.SS$nBandits,stanData.SS$choice,stanData.SS$shock)
#Simulate RW model
fit.rw <- readRDS('fits/v1/r1_RW.fit')
ex.rw <- rstan::extract(fit.rw)
ssLearn <- colMeans(ex.rw$alpha)
ss.simRW <- sim_rw(stanData.SS$nSubjects,stanData.SS$nTrials,stanData.SS$nBandits,stanData.SS$choice,stanData.SS$shock,ssLearn)
#Calculate feature differences (Option A - Option B)
SS.diff.meanBayes <- array(0,dim=c(stanData.SS$nSubjects,stanData.SS$nTrials))
SS.diff.varBayes <- array(0,dim=c(stanData.SS$nSubjects,stanData.SS$nTrials))
SS.diff.meanRW <- array(0,dim=c(stanData.SS$nSubjects,stanData.SS$nTrials))
SS.diff.orig <- array(0,dim=c(stanData.SS$nSubjects,stanData.SS$nTrials))
SS.diff.payoff <- array(0,dim=c(stanData.SS$nSubjects,stanData.SS$nTrials))
for (s in 1:stanData.SS$nSubjects){
for (t in 1:stanData.SS$nTrials){
SS.diff.meanBayes[s,t] = ss.simBayes$meanBayes[s,t,stanData.SS$option_A[s,t]]-ss.simBayes$meanBayes[s,t,stanData.SS$option_B[s,t]]
SS.diff.varBayes[s,t] = ss.simBayes$varBayes[s,t,stanData.SS$option_A[s,t]]-ss.simBayes$varBayes[s,t,stanData.SS$option_B[s,t]]
SS.diff.meanRW[s,t] = ss.simRW$meanRW[s,t,stanData.SS$option_A[s,t]]-ss.simRW$meanRW[s,t,stanData.SS$option_B[s,t]]
SS.diff.orig[s,t] = mes[stanData.SS$option_A[s,t]] - mes[stanData.SS$option_B[s,t]]
SS.diff.payoff[s,t] = payoff[stanData.SS$option_A[s,t]] - payoff[stanData.SS$option_B[s,t]]
}
}
data_ss <- data_ss %>% ungroup() %>% dplyr::mutate(diff.payoff=as.vector(t(SS.diff.payoff)),
diff.meanBayes=as.vector(t(SS.diff.meanBayes)),diff.varBayes=as.vector(t(SS.diff.varBayes)),
diff.meanRW=as.vector(t(SS.diff.meanRW)),diff.orig=as.vector(t(SS.diff.orig)),
optA=as.vector(t(stanData.SS$option_A)),optB=as.vector(t(stanData.SS$option_B)))
dataSS <- data_ss %>% dplyr::mutate(keyA = case_when(CSchosen==optA~1,CSchosen==optB~-1)) %>% filter(!is.na(RT),!is.na(SS)) #%>%
#mutate(across(c("keyA","diff.payoff","diff.orig","diff.meanRW","diff.meanBayes","diff.varBayes"), ~.x*-1))
for (row in 1:nrow(dataSS)){
if (dataSS$i[row] < .5){
dataSS$keyA[row] <- dataSS$keyA[row]*-1
dataSS$diff.payoff[row] <- dataSS$diff.payoff[row]*-1
dataSS$diff.orig[row] <- dataSS$diff.orig[row]*-1
dataSS$diff.meanRW[row] <- dataSS$diff.meanRW[row]*-1
dataSS$diff.meanBayes[row] <- dataSS$diff.meanBayes[row]*-1
dataSS$diff.varBayes[row] <- dataSS$diff.varBayes[row]*-1
}
}
dataSS <- dataSS %>% dplyr::mutate_at(c("keyA","Subject"),as.factor)
dataSS$ss_scaled <- scale(dataSS$SS)[,1]
#Fit Models
SS.modelOrig <- glmer(keyA ~ diff.payoff + diff.orig*ss_scaled + (1|Subject),data=dataSS,family = binomial)
SS.modelRW <- glmer(keyA ~ diff.payoff + diff.meanRW*ss_scaled + (1|Subject),data=dataSS,family = binomial)
SS.modelMeanBayes <- glmer(keyA ~ diff.payoff + diff.meanBayes*ss_scaled + (1|Subject),data=dataSS,family = binomial)
SS.modelVarBayes <- glmer(keyA ~ diff.payoff + diff.varBayes*ss_scaled + (1|Subject),data=dataSS,family = binomial)
#Model Comparison
glmer.MC <- data.frame(Model = c('Original','RW','BLmean','BLvar'),
value = c(AIC(SS.modelOrig),AIC(SS.modelRW),AIC(SS.modelMeanBayes),AIC(SS.modelVarBayes)))
modelOrder <- c("Original","RW","BLmean","BLvar")
aicPlot <- ggplot(glmer.MC, aes(x=factor(Model, level=rev(modelOrder)), y=value, fill=Model)) +
theme_classic() +
geom_bar(stat="identity", position=position_dodge(),size=3) +
ggtitle("Regression \n Model Comparision")+
xlab("Mixed-Effects Models")+
ylab("AIC (lower is better)") +
theme(legend.position = 'none',text=element_text(size=20)) +
scale_fill_manual(values = c("#0070c0","#cc79a7","#e79f00", "#019e73")) +
coord_flip()
#Model Prediction
SS.predictVarBayes <- ggemmeans(SS.modelVarBayes, terms =list(diff.varBayes=seq(-0.5,0.5,0.01),ss_scaled=c(-2,2)),type="fe")
SS.predictMeanBayes <- ggemmeans(SS.modelMeanBayes, terms =list(diff.meanBayes=seq(-1,1,0.01),ss_scaled=c(-2,2)),type="fe")
SS.predictRW <- ggemmeans(SS.modelRW, terms =list(diff.meanRW=seq(-1,1,0.01),ss_scaled=c(-2,2)),type="fe")
SS.predictOrig <- ggemmeans(SS.modelOrig, terms =list(diff.orig=c(-1,1),ss_scaled=c(-2,2)),type="fe")
#Plots
SS.plotVar <- ggplot(SS.predictVarBayes, aes(x=x,y=predicted,fill="#cc79a7")) +
geom_ribbon(aes(ymin=conf.low, ymax=conf.high,alpha=group,),color=NA) +
geom_line(aes(color="#cc79a7",linetype=group),size=1.2) +
theme_classic() +
labs(title="Bayesian Variance",x="Shock Uncertainty Difference \n (A-B)", y = "P(choice = A)") +
scale_alpha_manual(values=c(0.25,0.65),guide=F,name="Sensation-Seeking",labels = c("Low", "High")) +
scale_linetype_manual(values = c("dotted","solid"),name="Sensation-Seeking",labels = c("Low", "High")) +
scale_colour_manual(values = c("#cc79a7", "#cc79a7"),name="Sensation-Seeking",labels = c("Low", "High"),guide=F) +
scale_fill_manual(values = c("#cc79a7", "#cc79a7"),name="Sensation-Seeking",labels = c("Low", "High"),guide=F) +
ylim(0,1) +
theme(legend.position=c(1,1), legend.justification = c(1,1),text=element_text(size=20)) +
geom_hline(yintercept = 0.5, linetype="dashed", color='red', size=1)
SS.plotMean <- ggplot(SS.predictMeanBayes, aes(x=x,y=predicted,fill="#0070c0")) +
geom_ribbon(aes(ymin=conf.low, ymax=conf.high,alpha=group,),color=NA) +
geom_line(aes(color="#0070c0",linetype=group),size=1.2) +
theme_classic() +
labs(title="Bayesian Mean",x="Shock Mean Difference \n (A-B)", y = "P(choice = A)") +
scale_alpha_manual(values=c(0.25,0.65),guide=F,name="Sensation-Seeking",labels = c("Low", "High")) +
scale_linetype_manual(values = c("dotted","solid"),name="Sensation-Seeking",labels = c("Low", "High")) +
scale_colour_manual(values = c("#0070c0", "#0070c0"),name="Sensation-Seeking",labels = c("Low", "High"),guide=F) +
scale_fill_manual(values = c("#0070c0", "#0070c0"),name="Sensation-Seeking",labels = c("Low", "High"),guide=F) +
ylim(0,1) +
theme(legend.position= c(1,1), legend.justification = c(1,1),text=element_text(size=20)) + theme(legend.position = 'none') +
geom_hline(yintercept = 0.5, linetype="dashed", color='red', size=1)
SS.plotRW <- ggplot(SS.predictRW, aes(x=x,y=predicted,fill="#019e73")) +
geom_ribbon(aes(ymin=conf.low, ymax=conf.high,alpha=group,),color=NA) +
geom_line(aes(color="#019e73",linetype=group),size=1.2) +
theme_classic() +
labs(title="Rescorla-Wagner",x="Shock Mean Difference \n (A-B)", y = "P(choice = A)") +
scale_alpha_manual(values=c(0.25,0.65),guide=F,name="Sensation-Seeking",labels = c("Low", "High")) +
scale_linetype_manual(values = c("dotted","solid"),name="Sensation-Seeking",labels = c("Low", "High")) +
scale_colour_manual(values = c("#019e73", "#019e73"),name="Sensation-Seeking",labels = c("Low", "High"),guide=F) +
scale_fill_manual(values = c("#019e73", "#019e73"),name="Sensation-Seeking",labels = c("Low", "High"),guide=F) +
ylim(0,1) +
theme(legend.position= c(1,1), legend.justification = c(1,1),text=element_text(size=20)) + theme(legend.position = 'none') +
geom_hline(yintercept = 0.5, linetype="dashed", color='red', size=1)
SS.plotOrig <- ggplot(SS.predictOrig, aes(x=x,y=predicted,fill="#e79f00")) +
#geom_ribbon(aes(ymin=conf.low, ymax=conf.high,alpha=group,),color=NA) +
geom_line(aes(color="#e79f00",linetype=group),size=1.2) +
geom_point(color="#e79f00",size=3) +
geom_errorbar(aes(x=x,y = predicted,ymin=conf.low,ymax=conf.high,colour="#e79f00"),width=.1,size=1) +
theme_classic() +
labs(title="Original",x="MES Identity \n (A-B)", y = "P(choice = A)") +
scale_alpha_manual(values=c(0.25,0.65),guide=F,name="Sensation-Seeking",labels = c("Low", "High")) +
scale_linetype_manual(values = c("dotted","solid"),name="Sensation-Seeking",labels = c("Low", "High")) +
scale_colour_manual(values = c("#e79f00", "#e79f00"),name="Sensation-Seeking",labels = c("Low", "High"),guide=F) +
scale_fill_manual(values = c("#e79f00", "#e79f00"),name="Sensation-Seeking",labels = c("Low", "High"),guide=F) +
ylim(0,1) +
theme(legend.position= c(1,1), legend.justification = c(1,1),text=element_text(size=20)) + theme(legend.position = 'none') +
geom_hline(yintercept = 0.5, linetype="dashed", color='red', size=1)
plotSS <- SS.plotOrig + SS.plotRW + SS.plotMean + SS.plotVar + plot_layout(nrow=2,ncol=2,guides = "collect") & theme(legend.position = 'bottom')
summary(SS.modelOrig)
summary(SS.modelVarBayes)
setwd("../Desktop/sensationseeking_MABs/Exp2"
)
genAsyFull.fitAsyFull <- func.Fit(nSub,nRd,nT,nC,gen.AsyFull,"STANmodels/hierarchicalE2_AsyOmega.stan")
#Fitting simulated data for model/parameter recovery
rm(list=ls())
library(rstan)
load("simFits/envE2.RData")
nSub <- 10
simRewards <- env.E2[[1]][1:nSub,,,]
simStim <- env.E2[[2]][1:nSub,,,]
nRd <- dim(simRewards)[2]
nT <- dim(simRewards)[3]
nC <- dim(simRewards)[4]
load("simFits/genBehaviour.RData")
#Function to fit models. Takes generated object, extracts and fits using model PATH
func.Fit <- function(nSub,nRd,nT,nC,genObj,stanModel){
exGenObj <- rstan::extract(genObj)
dataGenObj <- list(nSub=nSub,nRd=nRd,nT=nT,nC=nC,
choice=exGenObj$y_pred[1,,,],
stim=exGenObj$stimulation[1,,,],
Rmu=exGenObj$Rmu_ts[1,,,,])
fitObj <- rstan::stan(file=stanModel,data=dataGenObj,
chains = 1, cores=4, iter=10,
seed=29061996,
verbose=F)
return(fitObj)
}
genAsyFull.fitAsyFull <- func.Fit(nSub,nRd,nT,nC,gen.AsyFull,"STANmodels/hierarchicalE2_AsyOmega.stan")
genAsyOmega.fitAsyFull <- func.Fit(nSub,nRd,nT,nC,gen.AsyOmega,"STANmodels/hierarchicalE2_AsyTheta.stan")
genAsyTheta.fitAsyFull <- func.Fit(nSub,nRd,nT,nC,gen.AsyTheta,"STANmodels/hierarchicalE2_Full.stan")
#Function to fit models. Takes generated object, extracts and fits using model PATH
func.Fit <- function(nSub,nRd,nT,nC,genObj,stanModel){
exGenObj <- rstan::extract(genObj)
dataGenObj <- list(nSub=nSub,nRd=nRd,nT=nT,nC=nC,
choice=exGenObj$y_pred[1,,,],
stim=exGenObj$stimulation[1,,,],
Rmu=exGenObj$Rmu_ts[1,,,,])
fitObj <- rstan::stan(file=stanModel,data=dataGenObj,
chains = 4, cores=4,
warmup = 2000, iter=4000,
seed=29061996,
verbose=F, save_warmup=F,
control = list(adapt_delta=.99))
return(fitObj)
}
Models <- c("AsySticky","AsyFull","AsyOmega","AsyTheta","Sticky","Full","Omega","Theta")
for (gen in 1:length(Models)){
for (fit in 1:length(Models)){
genObj.Name <- paste0("gen.",Models[gen])
genObj <- get(genObj.Name)
fitPath <- paste0("STANmodels/hierarchicalE2_",Models[fit],".stan")
print(paste("Fitting Model",fitPath,"to",genObj.Name))
fit.file <- func.Fit(nSub,nRd,nT,nC,genObj,fitPath)
saveRDS(fit.file,file=paste0("simFits/gen",Models[gen],"_fit",Models[fit],".fit"))
}
}
#Charley Wu
#Hierarchical sofmax predictions
rm(list=ls())
#Load packages
packages <- c( 'rstan', 'tidyr', 'dplyr' )
invisible(lapply(packages, require, character.only = TRUE))
#Define Error variance and model type
errorVarianceList <- c('Fixed') #For different variances of the BMT predictions; no longer used
#modelList <- c('alphaBeta', 'sticky', 'TUscaled')
modelList <- c('sticky')
# Command to distribute jobs on a server
combs <- expand.grid(1:length(errorVarianceList), 1:length(modelList))
View(combs)
clusterid <- as.integer(commandArgs(TRUE)[1])
if(is.na(clusterid)){clusterid<-sample(1:nrow(combs), 1)} #sample a random number if not provided=
comb <- combs[clusterid,]
errorVar <- errorVarianceList[comb$Var1]
model <- modelList[comb$Var2]
print(errorVar)
print(model)
set.seed(clusterid)
#Fitting simulated data for model/parameter recovery
rm(list=ls())
#Generate Behaviour Under Given Model
load("simFits/genParams.RData")
load("simFits/genBehaviour.RData")
#Fitting simulated data for model/parameter recovery
rm(list=ls())
source("C:/Users/ern_3/OneDrive/Desktop/ss_Exp2/SSexp2_fit.R", echo=TRUE)
